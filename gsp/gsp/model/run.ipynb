{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTS**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import pandas as pd\n",
    "from typing import Any, List, Literal, Tuple, TypeAlias, cast, Union\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from xgboost import XGBRegressor\n",
    "from gsp.model.utils import make_mw_in_groups, make_shift_in_groups, ColumnTransformerWrapper, show, get_nth_previous_working_date\n",
    "from data import SCRAPED_STOCK_FILE_PATH, save_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "def load_data() -> pd.DataFrame:\n",
    "    return pd.read_csv(\n",
    "        SCRAPED_STOCK_FILE_PATH,\n",
    "        dtype={\n",
    "            \"Date\": \"period[D]\",\n",
    "            \"Open\": \"float\",\n",
    "            \"High\": \"float\",\n",
    "            \"Low\": \"float\",\n",
    "            \"Close\": \"float\",\n",
    "            \"Volume\": \"int\",\n",
    "            \"Area\": \"category\",\n",
    "            \"Name\": \"category\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy(deep=True)\n",
    "    periods = pd.date_range(\n",
    "        start=df[\"Date\"].min().to_timestamp().date(), end=df[\"Date\"].max().to_timestamp().date(), freq=\"B\"\n",
    "    )\n",
    "    periods_df = pd.DataFrame({\"Date\": periods}, dtype=\"period[D]\")\n",
    "\n",
    "    clean_data = (\n",
    "        cast(\n",
    "            pd.DataFrame,\n",
    "            periods_df.set_index(\"Date\")\n",
    "            .join(df.set_index(\"Date\"))\n",
    "            .set_index(\"Name\", append=True)\n",
    "            .sort_index()\n",
    "            .unstack(\"Name\")\n",
    "            .ffill()\n",
    "            .stack(\"Name\", future_stack=True),  # type: ignore\n",
    "        )\n",
    "        .reset_index()\n",
    "        .dropna(subset=[\"Name\"])\n",
    "        .set_index([\"Date\", \"Name\"])\n",
    "    )\n",
    "\n",
    "    return clean_data\n",
    "\n",
    "\n",
    "def engineer_features(\n",
    "    df: pd.DataFrame,\n",
    "    categorical_features: List[str],\n",
    "    shift_list: List[int],\n",
    "    mwm_list: List[int],\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    if \"DayOfWeek\" in categorical_features:\n",
    "        df[\"DayOfWeek\"] = cast(pd.PeriodIndex, df.index.get_level_values(\"Date\")).dayofweek\n",
    "\n",
    "    if \"Month\" in categorical_features:\n",
    "        df[\"Month\"] = cast(pd.PeriodIndex, df.index.get_level_values(\"Date\")).month\n",
    "\n",
    "    if \"Year\" in categorical_features:\n",
    "        df[\"Year\"] = cast(pd.PeriodIndex, df.index.get_level_values(\"Date\")).year\n",
    "\n",
    "    if \"WeekOfYear\" in categorical_features:\n",
    "        df[\"WeekOfYear\"] = cast(pd.PeriodIndex, df.index.get_level_values(\"Date\")).week  # type: ignore\n",
    "\n",
    "    if \"DayOfMonth\" in categorical_features:\n",
    "        df[\"DayOfMonth\"] = cast(pd.PeriodIndex, df.index.get_level_values(\"Date\")).day\n",
    "\n",
    "    if \"Quarter\" in categorical_features:\n",
    "        df[\"Quarter\"] = cast(pd.PeriodIndex, df.index.get_level_values(\"Date\")).quarter\n",
    "\n",
    "    if \"AreaCat\" in categorical_features:\n",
    "        df[\"AreaCat\"] = df[\"Area\"]\n",
    "\n",
    "    grouped_lags: List[pd.DataFrame | pd.Series] = [\n",
    "        make_shift_in_groups(df, groupby=[\"Name\"], column=\"Close\", shift=shift_list),\n",
    "        make_mw_in_groups(df, groupby=[\"Name\"], column=\"Close\", window=mwm_list),\n",
    "    ]\n",
    "\n",
    "    df_grouped_lags = df.join(grouped_lags, how=\"left\")\n",
    "\n",
    "    return df_grouped_lags\n",
    "\n",
    "\n",
    "def process_data(\n",
    "    df: pd.DataFrame,\n",
    "    n_steps: int,\n",
    "    categorical_features: List[str],\n",
    "    starting_date_to_consider: datetime.date | None = None,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    \"\"\"First date where all stocks have data\"\"\"\n",
    "    first_all_valid_date: datetime.date = (\n",
    "        cast(pd.Period, df.unstack(\"Name\").dropna().first_valid_index()).to_timestamp().date()\n",
    "    )\n",
    "\n",
    "    earliest_date: datetime.date = first_all_valid_date\n",
    "\n",
    "    if starting_date_to_consider is not None and starting_date_to_consider < first_all_valid_date:\n",
    "        show(\n",
    "            f\"WARNING: starting_date_to_consider ({starting_date_to_consider}) is before the first date where all stocks have data. Using {first_all_valid_date} instead.\"\n",
    "        )\n",
    "    elif starting_date_to_consider is not None:\n",
    "        earliest_date = starting_date_to_consider\n",
    "\n",
    "    show(f\"Earliest date: {earliest_date.isoformat()}\")\n",
    "\n",
    "    ctw = ColumnTransformerWrapper(\n",
    "        transformers=[\n",
    "            (\"onehot\", OneHotEncoder(), categorical_features),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "\n",
    "    X = ctw.fit_transform(df.drop(columns=[\"Adj Close\", \"Volume\", \"High\", \"Low\", \"Open\", \"Area\"])).loc[\n",
    "        earliest_date.isoformat() :\n",
    "    ]\n",
    "    y = make_shift_in_groups(df, groupby=[\"Name\"], column=\"Close\", shift=[-i for i in range(1, n_steps + 1)])\n",
    "\n",
    "    y, X = y.align(X.dropna(), axis=0, join=\"inner\")\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def split_data(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.DataFrame,\n",
    "    n_steps: int,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"A function that splits the time series data into train and test sets in regards\n",
    "    to the number of forecasting steps. It will test the model on the last 2*n_steps.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): Features dataframe\n",
    "        y (pd.DataFrame): Target dataframe\n",
    "        n_steps (int): Number of steps of the forecasting task\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]: X_train, y_train, X_test, y_test\n",
    "    \"\"\"\n",
    "    latest_date = cast(pd.Period, X.index.get_level_values(\"Date\").max()).to_timestamp().date()\n",
    "    test_end_date = get_nth_previous_working_date(n=n_steps, date=latest_date)\n",
    "    test_start_date = get_nth_previous_working_date(n=2 * n_steps - 1, date=latest_date)\n",
    "    train_end_date = get_nth_previous_working_date(n=2 * n_steps, date=latest_date)\n",
    "\n",
    "    X_train = X.loc[: train_end_date.isoformat()]\n",
    "    y_train = y.loc[: train_end_date.isoformat()]\n",
    "    X_test = X.loc[test_start_date.isoformat() : test_end_date.isoformat()]\n",
    "    y_test = y.loc[test_start_date.isoformat() : test_end_date.isoformat()]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def create_model(**hyper_params):\n",
    "    model = RegressorChain(XGBRegressor(**hyper_params))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def fit_and_predict(\n",
    "    model: Union[RegressorChain, MultiOutputRegressor, LinearRegression],\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    X_query: pd.DataFrame,\n",
    "):\n",
    "    model = model.fit(X_train, y_train)\n",
    "    y_pred = pd.DataFrame(model.predict(X_query), index=X_query.index, columns=y_train.columns)  # type: ignore\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def convert_last_prediction_to_output(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    latest_date = cast(pd.Period, df.index.get_level_values(\"Date\").max()).to_timestamp().date()\n",
    "\n",
    "    y_latest = cast(pd.DataFrame, df.loc[latest_date.isoformat()]).rename(\n",
    "        columns={\n",
    "            f\"Close_lead_{i}\": get_nth_previous_working_date(n=-i, date=latest_date).isoformat()\n",
    "            for i in range(1, len(df.columns) + 1)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    y_output = (\n",
    "        y_latest\n",
    "        .reset_index()\n",
    "        .melt(id_vars=[\"Name\"], var_name=\"Date\", value_name=\"Close\")\n",
    "        .astype({\n",
    "            \"Date\": \"period[D]\",\n",
    "            \"Name\": \"category\",\n",
    "            \"Close\": \"float\",\n",
    "        })\n",
    "        .set_index([\"Date\", \"Name\"])\n",
    "    )\n",
    "\n",
    "    return y_output\n",
    "\n",
    "\n",
    "def execute_test_run(\n",
    "    n_steps: int, \n",
    "    categorical_features: List[str], \n",
    "    hyper_params: Dict = {}\n",
    ") ->Tuple[pd.DataFrame, pd.DataFrame, float]:\n",
    "\n",
    "    stocks = load_data()\n",
    "    clean = clean_data(stocks)\n",
    "    features = engineer_features(clean, categorical_features, shift_list=[1], mwm_list=[5])\n",
    "    X, y = process_data(features, n_steps, categorical_features)\n",
    "    X_train, y_train, X_test, y_test = split_data(X, y, n_steps)\n",
    "    model = create_model(**hyper_params)\n",
    "    y_test_pred = fit_and_predict(model, X_train, y_train, X_test)\n",
    "    rmsle = cast(float, mean_squared_log_error(y_test, y_test_pred, squared=False))\n",
    "\n",
    "    y_test_output = convert_last_prediction_to_output(y_test_pred)\n",
    "    show(f\"Root Mean Squared Log Error: {rmsle}\")\n",
    "\n",
    "    return features, y_test_output, rmsle\n",
    "\n",
    "\n",
    "def execute_real_run(n_steps: int, categorical_features: List[str]) -> Tuple[pd.DataFrame, datetime.date]:\n",
    "\n",
    "    stocks = load_data()\n",
    "    clean = clean_data(stocks)\n",
    "    features = engineer_features(clean, categorical_features, shift_list=[1], mwm_list=[5])\n",
    "    X, y = process_data(features, n_steps, categorical_features)\n",
    "    X_train, y_train = X.align(y.dropna(), axis=0, join=\"inner\")\n",
    "\n",
    "    prediction_date = cast(pd.Period, X.index.get_level_values(\"Date\").max()).to_timestamp().date()\n",
    "    X_query = X.loc[prediction_date.isoformat() :]\n",
    "\n",
    "    model = create_model()\n",
    "    y_pred = fit_and_predict(model, X_train, y_train, X_query)\n",
    "    y_output = convert_last_prediction_to_output(y_pred)\n",
    "\n",
    "    return y_output, prediction_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FORECASTING PROBLEM DEFINITION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps : int = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEST EXECUTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, y_test_output, rmsle = execute_test_run(n_steps=n_steps, categorical_features=[\"DayOfWeek\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diplay_last_n_days = 150\n",
    "unique_names = y_test_output.index.get_level_values(\"Name\").unique()\n",
    "for name in unique_names:\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    fig.suptitle(name)\n",
    "    \n",
    "    cast(\n",
    "        pd.DataFrame,\n",
    "        features[features.index.get_level_values(\"Name\") == name]\n",
    "    ).reset_index(\"Name\")[\"Close\"].tail(diplay_last_n_days).plot(label=f\"Close for {name}\", ax = fig.gca())\n",
    "\n",
    "    cast(\n",
    "        pd.DataFrame,\n",
    "        y_test_output[y_test_output.index.get_level_values(\"Name\") == name]\n",
    "    ).reset_index(\"Name\")[\"Close\"].plot(label=f\"Predicted Close for {name}\", ax = fig.gca())\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REAL EXECUTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Earliest date: 2004-08-20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_real_output, prediction_date = execute_real_run(n_steps=n_steps, categorical_features=[\"DayOfWeek\"])\n",
    "save_output(y_real_output, f\"{prediction_date.isoformat()}_prediction_{n_steps}_steps.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsp-NqpUKMXU-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
