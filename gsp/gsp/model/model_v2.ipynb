{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Literal, Tuple, TypeAlias, cast\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from data import SCRAPED_STOCK_FILE_PATH\n",
    "import logging\n",
    "from gsp.model.utils import (\n",
    "    get_minimal_stocks_existence_date,\n",
    "    get_nth_previous_working_date,\n",
    "    show,\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor, RegressorChain\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "YEARS_BACK_TO_CONSIDER = 3\n",
    "N_STEP_PREDICTION = 22\n",
    "\n",
    "stocks =  pd.read_csv(\n",
    "    SCRAPED_STOCK_FILE_PATH,\n",
    "    dtype={\n",
    "        \"Date\": \"period[D]\",\n",
    "        \"Open\": \"float\",\n",
    "        \"High\": \"float\",\n",
    "        \"Low\": \"float\",\n",
    "        \"Close\": \"float\",\n",
    "        \"Volume\": \"int\",\n",
    "        \"Area\": \"category\",\n",
    "        \"Name\": \"category\",\n",
    "    },\n",
    ")\n",
    "\n",
    "periods = pd.date_range(\n",
    "    start=stocks[\"Date\"].min().to_timestamp().date(), \n",
    "    end=stocks[\"Date\"].max().to_timestamp().date(), \n",
    "    freq=\"B\"\n",
    ")\n",
    "periods_df = pd.DataFrame({\"Date\": periods}, dtype=\"period[D]\")\n",
    "diff_periods = periods_df[~periods_df[\"Date\"].isin(stocks[\"Date\"])]\n",
    "# show(\"Missing working holidays days: \",diff_periods)\n",
    "\n",
    "cleaned = (cast(\n",
    "    pd.DataFrame,\n",
    "    periods_df.set_index(\"Date\")\n",
    "    .join(stocks.set_index(\"Date\"))\n",
    "    .set_index(\"Name\", append=True)\n",
    "    .sort_index()\n",
    "    .unstack(\"Name\")\n",
    "    .ffill()\n",
    "    .stack(\"Name\", future_stack=True)) # type: ignore\n",
    "    .reset_index()\n",
    "    .dropna(subset=[\"Name\"])\n",
    "    .set_index([\"Date\", \"Name\"])\n",
    ")\n",
    "\n",
    "\n",
    "def make_shift_in_groups(\n",
    "    df: pd.DataFrame,\n",
    "    groupby: List[str] = [],\n",
    "    column: str = \"\",\n",
    "    shift: List[int] | int = 1,\n",
    "    name: str | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    df = df.copy(deep=True)\n",
    "    if name is None:\n",
    "        name = column\n",
    "\n",
    "    if isinstance(shift, int):\n",
    "        shift = [shift]\n",
    "\n",
    "    shift = list(filter(lambda el: el != 0, shift))\n",
    "\n",
    "    if len(shift) == 0:\n",
    "        raise ValueError(\"Shift value must be non-zero!\")\n",
    "\n",
    "    def create_shifted_columns(group):\n",
    "        shifted_group = pd.DataFrame(index=group.index)\n",
    "        for val in shift:\n",
    "\n",
    "            shifted_group[f\"{name}_{'lead' if val < 0 else 'lag'}_{abs(val)}\"] = group[column].shift(val)\n",
    "\n",
    "        return shifted_group\n",
    "\n",
    "    shifted_df = cast(\n",
    "        pd.DataFrame,\n",
    "        df.groupby(groupby, observed=True, group_keys=False)\n",
    "        .apply(create_shifted_columns, include_groups=False)\n",
    "        .sort_index(),\n",
    "    )\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "\n",
    "MOVING_WINDOW_AGGREGATORS_ALIAS: TypeAlias = Literal[\"mean\", \"sum\", \"median\", \"std\", \"var\"]\n",
    "\n",
    "\n",
    "def make_mw_in_groups(\n",
    "    df: pd.DataFrame,\n",
    "    groupby: List[str] = [],\n",
    "    column: str = \"\",\n",
    "    window: List[int] | int = 30,\n",
    "    center: List[bool] | bool = False,\n",
    "    min_periods: List[int] | int = 1,\n",
    "    aggregator: List[MOVING_WINDOW_AGGREGATORS_ALIAS] | MOVING_WINDOW_AGGREGATORS_ALIAS = \"mean\",\n",
    "    name: str | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    df = df.copy(deep=True)\n",
    "    if name is None:\n",
    "        name = column\n",
    "\n",
    "    if isinstance(window, int):\n",
    "        window = [window]\n",
    "\n",
    "    window = list(filter(lambda x: x != 0, window))\n",
    "    if len(window) == 0:\n",
    "        raise ValueError(\"Window value must be non-zero!\")\n",
    "    if isinstance(center, bool):\n",
    "        center = [center] * len(window)\n",
    "    if isinstance(min_periods, int):\n",
    "        min_periods = [min_periods] * len(window)\n",
    "    if isinstance(aggregator, str):\n",
    "        aggregator = cast(List[MOVING_WINDOW_AGGREGATORS_ALIAS], [aggregator]) * len(window)\n",
    "\n",
    "    def create_mw_columns(group):\n",
    "        ma_group = pd.DataFrame(index=group.index)\n",
    "        for index, val in enumerate(window):\n",
    "            type_name = \"lag\" if val > 0 else \"lead\"\n",
    "            if val < 0:\n",
    "                ma_group[f\"{name}_{type_name}_{aggregator[index]}_{-val}\"] = (\n",
    "                    group[column]\n",
    "                    .rolling(window=-val, center=center[index], min_periods=min_periods[index])\n",
    "                    .aggregate(aggregator[index])\n",
    "                    .shift(val)\n",
    "                )\n",
    "            else:\n",
    "                ma_group[f\"{name}_{type_name}_{aggregator[index]}_{val}\"] = (\n",
    "                    group[column]\n",
    "                    .shift(1)\n",
    "                    .rolling(window=val, center=center[index], min_periods=min_periods[index])\n",
    "                    .aggregate(aggregator[index])\n",
    "                )\n",
    "\n",
    "        return ma_group\n",
    "\n",
    "    return cast(\n",
    "        pd.DataFrame,\n",
    "        df.groupby(groupby, observed=True, group_keys=False)\n",
    "        .apply(create_mw_columns, include_groups=False)\n",
    "        .sort_index(),\n",
    "    )\n",
    "\n",
    "\n",
    "# categorical_features = [\"DayOfWeek\", \"NameCat\", \"Month\", \"Year\", \"Quarter\", \"Area\"]\n",
    "categorical_features = [\"DayOfWeek\", \"Year\"]\n",
    "stocks_pre_processed = cleaned.copy()\n",
    "\n",
    "if \"DayOfWeek\" in categorical_features:\n",
    "    stocks_pre_processed[\"DayOfWeek\"] = stocks_pre_processed.index.get_level_values(\"Date\").dayofweek\n",
    "\n",
    "if \"Month\" in categorical_features:\n",
    "    stocks_pre_processed[\"Month\"] = stocks_pre_processed.index.get_level_values(\"Date\").month\n",
    "\n",
    "if \"Year\" in categorical_features:\n",
    "    stocks_pre_processed[\"Year\"] = stocks_pre_processed.index.get_level_values(\"Date\").year\n",
    "\n",
    "if \"Quarter\" in categorical_features:\n",
    "    stocks_pre_processed[\"Quarter\"] = stocks_pre_processed.index.get_level_values(\"Date\").quarter\n",
    "\n",
    "if \"NameCat\" in categorical_features:\n",
    "    stocks_pre_processed[\"NameCat\"] = stocks_pre_processed.index.get_level_values(\"Name\").astype(\"category\")\n",
    "\n",
    "if not (\"Area\" in categorical_features):\n",
    "    stocks_pre_processed = stocks_pre_processed.drop(columns=[\"Area\"])\n",
    "\n",
    "grouped_lags_list : List[pd.DataFrame | pd.Series] = [\n",
    "    make_shift_in_groups(\n",
    "        df=stocks_pre_processed,\n",
    "        groupby=[\"Name\"],\n",
    "        column=\"Close\",\n",
    "        shift=[1]\n",
    "    ),\n",
    "    make_mw_in_groups(\n",
    "        df=stocks_pre_processed,\n",
    "        groupby=[\"Name\"],\n",
    "        column=\"Close\",\n",
    "        window=[5, 60],\n",
    "        aggregator=\"mean\"\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "stocks_post_processed = stocks_pre_processed.join(grouped_lags_list)\n",
    "# stocks_post_processed[\"GrowingMeanRate\"] = stocks_post_processed[\"Close_lag_mean_5\"] / stocks_post_processed[\"Close_lag_mean_60\"]\n",
    "\n",
    "most_recent_date = cast(datetime.date, stocks_pre_processed.index.get_level_values(\"Date\").max().to_timestamp().date())\n",
    "earliest_considerable_date = get_nth_previous_working_date(YEARS_BACK_TO_CONSIDER * 261, most_recent_date)\n",
    "all_existence_date = get_minimal_stocks_existence_date(stocks)\n",
    "\n",
    "least_recent_date = max(earliest_considerable_date, all_existence_date)\n",
    "\n",
    "# show(\n",
    "#     f\"most_recent_date: {most_recent_date}\",\n",
    "#     f\"earliest_considerable_date: {earliest_considerable_date}\",\n",
    "#     f\"all_existence_date: {all_existence_date}\",\n",
    "#     f\"least_recent_date: {least_recent_date}\",\n",
    "# )\n",
    "\n",
    "# filter stocks_limited if you want to solve for single problem\n",
    "stocks_limited = stocks_post_processed.loc[least_recent_date.isoformat() : most_recent_date.isoformat()]\n",
    "stocks_limited = stocks_limited.loc[stocks_limited.index.get_level_values(\"Name\").isin([\"MSFT\"])]\n",
    "@dataclass\n",
    "class ColumnTransformerWrapper:\n",
    "    transformers: List[Tuple[str, Any, List[str]]]\n",
    "    remainder: Literal[\"drop\", \"passthrough\"] = \"passthrough\"\n",
    "\n",
    "    def fit_transform(self, X: pd.DataFrame, y: Any | None = None) -> pd.DataFrame:  # type: ignore\n",
    "        ct = ColumnTransformer(self.transformers, remainder=self.remainder)\n",
    "\n",
    "        return pd.DataFrame(\n",
    "            ct.fit_transform(X, y),  # type: ignore\n",
    "            index=X.index,\n",
    "            columns=[col.replace(\"remainder__\", \"\") for col in ct.get_feature_names_out()],\n",
    "        )\n",
    "\n",
    "\n",
    "ctw = ColumnTransformerWrapper(\n",
    "    transformers=[\n",
    "        (\"one_hot\", OneHotEncoder(drop=\"first\", sparse_output=False), categorical_features),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "X_encoded = ctw.fit_transform(stocks_limited)\n",
    "\n",
    "\n",
    "X = X_encoded.drop(columns=[\"Adj Close\", \"Open\", \"High\",\"Low\", \"Volume\"])\n",
    "\n",
    "\n",
    "y = make_shift_in_groups(df=stocks_limited, groupby=[\"Name\"], column=\"Close\",shift=[-i for i in range(1, N_STEP_PREDICTION+1)])\n",
    "\n",
    "y, X = y.align(X.dropna(), axis=0, join=\"inner\")\n",
    "start_training_date = least_recent_date\n",
    "end_training_date = get_nth_previous_working_date(n=3*N_STEP_PREDICTION, date=most_recent_date)\n",
    "start_testing_date = get_nth_previous_working_date(n=-N_STEP_PREDICTION, date=end_training_date)\n",
    "end_testing_date = get_nth_previous_working_date(n=N_STEP_PREDICTION, date=most_recent_date)\n",
    "\n",
    "\n",
    "show(\n",
    "    f\"start_training_date: {start_training_date}\",\n",
    "    f\"end_training_date: {end_training_date}\",\n",
    "    f\"start_testing_date: {start_testing_date}\",\n",
    "    f\"end_testing_date: {end_testing_date}\",\n",
    ")\n",
    "\n",
    "\n",
    "X_train = X.loc[start_training_date.isoformat() : end_training_date.isoformat()]\n",
    "y_train = y.loc[start_training_date.isoformat() : end_training_date.isoformat()]\n",
    "X_test = X.loc[start_testing_date.isoformat() : end_testing_date.isoformat()]\n",
    "y_test = y.loc[start_testing_date.isoformat() : end_testing_date.isoformat()]\n",
    "\n",
    "show(\"FULL PROCESSED DATA\")\n",
    "show(X.columns)\n",
    "show(y.columns)\n",
    "\n",
    "show(\"TRAINING DATA\")\n",
    "show(X_train.columns)\n",
    "show(y_train.columns)\n",
    "\n",
    "\n",
    "hyper_params = {}\n",
    "\n",
    "model = RegressorChain(XGBRegressor(**hyper_params))\n",
    "# model = MultiOutputRegressor(XGBRegressor(**hyper_params))\n",
    "# model = LinearRegression()\n",
    "# model = RegressorChain(base_estimator=lgb.LGBMRegressor()) # type: ignore\n",
    "\n",
    "logger.info(\"Training the model...\")\n",
    "show(\"TRAINING DATA X\", X_train.tail(30))\n",
    "show(\"TRAINING DATA y\", y_train.tail(30))\n",
    "model.fit(X_train, y_train)\n",
    "logger.info(\"Model trained successfully\")\n",
    "\n",
    "y_pred = pd.DataFrame(model.predict(X_test), index=X_test.index, columns=y.columns) # type: ignore\n",
    "\n",
    "y_latest = y_pred.loc[y_pred.index.get_level_values(\"Date\").max().to_timestamp().date().isoformat() :]\n",
    "\n",
    "\n",
    "def convert_to_output(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy(deep=True)\n",
    "    last_date = df.index.get_level_values(\"Date\").max().to_timestamp().date()\n",
    "\n",
    "    df_renamed = df.rename(\n",
    "        columns={\n",
    "            f\"Close_lead_{i}\": get_nth_previous_working_date(n=-i, date=last_date)\n",
    "            for i in range(1, N_STEP_PREDICTION + 1)\n",
    "        }\n",
    "    )\n",
    "    df_melted = (\n",
    "        df_renamed.reset_index(\"Name\")\n",
    "        .melt(id_vars=[\"Name\"], var_name=\"Date\", value_name=\"Close\")\n",
    "        .astype(\n",
    "            {\n",
    "                \"Date\": \"period[D]\",\n",
    "                \"Name\": \"category\",\n",
    "                \"Close\": \"float\",\n",
    "            }\n",
    "        )\n",
    "        .set_index([\"Date\", \"Name\"])\n",
    "    )\n",
    "\n",
    "    return df_melted\n",
    "\n",
    "\n",
    "y_output = y_latest.groupby(\"Name\", observed=True, group_keys=False).apply(convert_to_output).sort_index()\n",
    "\n",
    "\n",
    "show(\"PREDICTION\", y_pred.tail(3))\n",
    "show(\"TEST\", y_test.tail(3))\n",
    "\n",
    "stocks_ids = stocks_limited.index.get_level_values(\"Name\").unique()\n",
    "\n",
    "for stock_id in stocks_ids:\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    fig.suptitle(stock_id)\n",
    "    stocks_limited.loc[\n",
    "        (\n",
    "            stocks_limited.index.get_level_values(\"Date\")\n",
    "            >= get_nth_previous_working_date(n=200, date=start_testing_date).isoformat()\n",
    "        )\n",
    "        & (stocks_limited.index.get_level_values(\"Name\") == stock_id)\n",
    "    ][[\"Close\"]].reset_index(\"Name\", drop=True).plot(ax=fig.gca(), legend=True)\n",
    "    y_output.loc[y_output.index.get_level_values(\"Name\") == stock_id][[\"Close\"]].reset_index(\"Name\", drop=True).plot(\n",
    "        ax=fig.gca(), legend=True, style=\"--\", color=\"red\"\n",
    "    )\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsp-xcVphxGa-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
